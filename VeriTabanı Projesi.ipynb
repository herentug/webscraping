{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semt: atasehir Sayfa : 1\n",
      "Processing... 3\n",
      "Processing... 8\n",
      "Processing... 13\n",
      "Processing... 18\n",
      "Semt: atasehir Sayfa : 2\n",
      "Processing... 27\n",
      "Processing... 32\n",
      "Processing... 37\n",
      "Processing... 42\n",
      "Semt: atasehir Sayfa : 3\n",
      "Processing... 51\n",
      "Processing... 56\n",
      "Processing... 61\n",
      "Processing... 66\n",
      "Semt: atasehir Sayfa : 4\n",
      "Processing... 75\n",
      "Processing... 80\n",
      "Processing... 81\n",
      "Processing... 85\n",
      "Processing... 90\n",
      "Semt: atasehir Sayfa : 5\n",
      "Processing... 99\n",
      "Processing... 104\n",
      "Processing... 109\n",
      "Processing... 114\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as soup  # HTML data structure\n",
    "from urllib import urlopen as uReq  # Web client\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "semts=[\"atasehir\",\"beykoz\",\"cekmekoy\",\"kadikoy\",\"kartal\",\"kucukcekmece\",\"maltepe\",\"pendik\",\"sancaktepe\",\"sultanbeyli\",\"sile\",\"tuzla\",\"umraniye\",\"uskudar\"]\n",
    "\n",
    "\n",
    "def strToNum(s):\n",
    "    i=s.find('.')\n",
    "    if(i!=-1):\n",
    "        s=s[0:i] + s[i+1:]\n",
    "    return int(s)/20\n",
    "for semt in semts:\n",
    "    page_url = \"https://www.hurriyetemlak.com/\"+semt+\"-satilik\"\n",
    "\n",
    "    buildings=[]\n",
    "    count=0\n",
    "    page_limit=2\n",
    "    page=1\n",
    "    while (page != page_limit):\n",
    "        pagesUrl=page_url+\"?page=\"+str(page)\n",
    "        print(\"Semt: \"+semt+\" Sayfa : \" + str(page))\n",
    "\n",
    "\n",
    "        # opens the connection and downloads html page from url\n",
    "        uClient = uReq(page_url)\n",
    "\n",
    "        page_soup = soup(uClient.read(), \"html.parser\")\n",
    "        uClient.close()\n",
    "        rows=page_soup.findAll(\"div\",{\"class\":\"list-item timeshare clearfix\"})\n",
    "        \n",
    "        if(page==1):\n",
    "            numberofPost=page_soup.findAll(\"strong\",{\"data-ads-count\":\"\"})\n",
    "            page_limit=strToNum(numberofPost[5].text)\n",
    "\n",
    "        for r in rows:\n",
    "            suburl=\"https://www.hurriyetemlak.com\"+r.a[\"href\"]\n",
    "            count+=1\n",
    "            try:\n",
    "                RuClient= uReq(suburl)\n",
    "            except:\n",
    "                print(\"Processing... \"+ str(count))\n",
    "                continue\n",
    "            page_detail = soup(RuClient.read(),\"html.parser\")\n",
    "            RuClient.close()\n",
    "            \n",
    "            try:\n",
    "                price=page_detail.find(\"li\",{\"class\":\"price-line clearfix\"})\n",
    "                pr = price.span.text\n",
    "                adress=page_detail.find(\"li\",{\"class\":\"address-line\"})\n",
    "                add = adress.span.text\n",
    "                info=dict()\n",
    "                \n",
    "                phones=page_detail.find(\"ul\",{\"class\":\"phone-numbers\"})\n",
    "\n",
    "                info[\"Telefon No\"]=phones.li.a.text\n",
    "\n",
    "                ilanID= page_detail.find(\"li\",{\"class\":\"realty-numb\"})\n",
    "\n",
    "                idModi=ilanID.span.text[8:-1]\n",
    "                info[\"Ilan No\"]=idModi\n",
    "                \n",
    "\n",
    "                info[\"BaslÄ±k\"]=page_detail.h1.text\n",
    "                info[\"Fiyat\"]=pr\n",
    "                add=add.replace('\\n','')\n",
    "                v=add.split('/')\n",
    "                info[\"Sehir\"]=v[0]\n",
    "                info[\"Semt\"]=v[1]\n",
    "                info[\"Mahalle\"]=v[2]\n",
    "                infos=page_detail.findAll(\"li\",{\"class\":\"info-line\"})\n",
    "                infoList=infos[0].ul.findAll(\"li\")\n",
    "                for i in range(0,len(infoList)-1):\n",
    "                    rc=infoList[i].findAll(\"span\")\n",
    "                    s=rc[1].text\n",
    "                    if(s[0:5]==\"Uygun\"):\n",
    "                        s=\"Uygun\"\n",
    "                    info[rc[0].text]=s\n",
    "                buildings.append(info)\n",
    "            except:\n",
    "                continue\n",
    "        page+=1\n",
    "    df=pd.DataFrame.from_records(buildings)\n",
    "    df.to_excel(semt+\".xlsx\",sheet_name=\"Sheet_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'612'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strToNum(\"612\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
